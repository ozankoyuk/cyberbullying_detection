{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for pre-processing data:  29.39s\n",
      "Elapsed time for preparing models:  5.76s\n",
      "            Algorithm  Accuracy (%)  Probability (%)  Total Time (s) \n",
      "0       Random Forest         92.74            79.25             8.77\n",
      "1  XGBoost (MLogLoss)         92.08            75.63           242.24\n",
      "2       Decision Tree         90.60            80.99             2.12\n",
      "3  AdaBoost Algorithm         39.40           100.00             2.22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time \n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from cleaner import get_processed_df, get_cyberbully_prob\n",
    "\n",
    "seed_value = 20230337\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "def fit_model(clf, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "    return accuracy, y_pred\n",
    "\n",
    "MAX_TWEET_LENGTH = 100\n",
    "df = get_processed_df(MAX_TWEET_LENGTH)\n",
    "\n",
    "# split the data into test and train \n",
    "X = df['text_clean']\n",
    "y = df['sentiment']\n",
    "\n",
    "# train and test splitting: \n",
    "# %20 -> Test\n",
    "# %80 -> Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(X), \n",
    "    y, \n",
    "    test_size = 0.2, \n",
    "    stratify = y, \n",
    "    random_state = seed_value\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "# TF-IDF: Term Frequency-Inverse Document Frequency\n",
    "# shows the importance of a word in the document\n",
    "#       number of times the word appears in the document \n",
    "# TF = ---------------------------------------------------\n",
    "#           total number of words in the document\n",
    "#\n",
    "#                  number of documents in the corpus\n",
    "# IDF = log(-----------------------------------------------) \n",
    "#            number of documents that contains the word +1\n",
    "#\n",
    "# TF-IDF = TF * IDF\n",
    "frequency_matrix = TfidfVectorizer(\n",
    "    use_idf = True, \n",
    "    tokenizer = word_tokenize,\n",
    "    min_df = 0.00002,\n",
    "    max_df = 0.70\n",
    ")\n",
    "\n",
    "# convert X_train and X_test into unicode\n",
    "# and then to a matrix of TF-IDF features\n",
    "X_train_tf = frequency_matrix.fit_transform(\n",
    "    X_train.astype('U')\n",
    ")\n",
    "X_test_tf = frequency_matrix.transform(\n",
    "    X_test.astype('U')\n",
    ")\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    criterion='gini',\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=2,\n",
    ")\n",
    "\n",
    "ada_boost = AdaBoostClassifier(\n",
    "    random_state=42,\n",
    "    learning_rate=0.0000005\n",
    ")\n",
    "\n",
    "# possible metrics : mlogloss, logloss, mae, mape, auc\n",
    "# all metrics will give the same result in my case\n",
    "xg_boost_mlogloss = XGBClassifier(\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    "    eta=0.0000005,\n",
    "    max_depth=10\n",
    ")\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=2,\n",
    ")\n",
    "\n",
    "perceptron_algorithm = MLPClassifier(\n",
    "    random_state=42,\n",
    "    hidden_layer_sizes=(100,),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "print(f\"Elapsed time for preparing models:  {round(time.time()-start, 2)}s\")\n",
    "\n",
    "algorithms = {\n",
    "    \"Random Forest\": random_forest,\n",
    "    \"XGBoost (MLogLoss)\": xg_boost_mlogloss,\n",
    "    \"Decision Tree\": decision_tree,\n",
    "    \"AdaBoost Algorithm\": ada_boost\n",
    "    # multilayer perceptron takes too much time to perfom\n",
    "    #\"Multilayer Perceptron\": perceptron_algorithm\n",
    "}\n",
    "\n",
    "accuracy_list = []\n",
    "probability_list = []\n",
    "time_list = []\n",
    "\n",
    "for name, _model in algorithms.items():\n",
    "    start = time.time()\n",
    "    # fit train and test data\n",
    "    curr_acc, predicted_list = fit_model(\n",
    "        _model, \n",
    "        X_train_tf, \n",
    "        y_train, \n",
    "        X_test_tf, \n",
    "        y_test\n",
    "    )\n",
    "    \n",
    "    # add accuracy, probability and the time values\n",
    "    accuracy_list.append(curr_acc)\n",
    "    probability_list.append(get_cyberbully_prob(predicted_list))\n",
    "    time_list.append(\n",
    "        round(time.time()-start, 2)\n",
    "    )\n",
    "\n",
    "# show every data in a table\n",
    "models_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Algorithm\" : algorithms.keys(),\n",
    "        \"Accuracy (%)\" : accuracy_list,\n",
    "        \"Probability (%)\" : probability_list,\n",
    "        \"Total Time (s) \" : time_list\n",
    "    }\n",
    ").sort_values(\"Accuracy (%)\", ascending=False)\n",
    "print(models_df)\n",
    "\n",
    "#\n",
    "#  ___                   _  __                 _    \n",
    "# / _ \\ ______ _ _ __   | |/ /___  _   _ _   _| | __\n",
    "#| | | |_  / _` | '_ \\  | ' // _ \\| | | | | | | |/ /\n",
    "#| |_| |/ / (_| | | | | | . \\ (_) | |_| | |_| |   < \n",
    "# \\___//___\\__,_|_| |_| |_|\\_\\___/ \\__, |\\__,_|_|\\_\\\n",
    "#                                  |___/            \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "new_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
