{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : Naive Bayes\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    religion       0.82      0.97      0.89      1581\n",
      "         age       0.78      0.98      0.87      1567\n",
      "   ethnicity       0.88      0.92      0.90      1548\n",
      "      gender       0.88      0.86      0.87      1467\n",
      "not bullying       0.87      0.38      0.53      1281\n",
      "\n",
      "    accuracy                           0.84      7444\n",
      "   macro avg       0.85      0.82      0.81      7444\n",
      "weighted avg       0.85      0.84      0.82      7444\n",
      "\n",
      "Elapsed time in seconds for Naive-Bayes:  28.67s\n",
      "Considering the tweets of the user, \n",
      "it was decided that this user is a cyberbully with:\n",
      "Probability\t92.54%\n",
      "Accuracy\t83.81%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import time \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from cleaner import start_cleaning, get_cyberbully_prob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "seed_value = 20230337\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "df = pd.read_csv(\"cyberbullying_tweets.csv\")\n",
    "df = df.rename(columns={'tweet_text': 'text', 'cyberbullying_type': 'sentiment'})\n",
    "\n",
    "# find duplicated ones and clear them\n",
    "df.duplicated().sum()\n",
    "df = df[~df.duplicated()]\n",
    "\n",
    "# show categorical data counts\n",
    "df.sentiment.value_counts()\n",
    "\n",
    "texts_new = start_cleaning(df)\n",
    "\n",
    "df['tweet_clean'] = texts_new\n",
    "df.head()\n",
    "df[\"tweet_clean\"].duplicated().sum()\n",
    "# clean duplicate data\n",
    "df.drop_duplicates(\"tweet_clean\", inplace=True)\n",
    "# show sentiment counts\n",
    "df.sentiment.value_counts()\n",
    "\n",
    "# removing other_cyberbullying categories will improve performance (%74 to %83)\n",
    "# because all the tweets in that category is actually contains the tweets that\n",
    "# can be any of the other categories (age, ethnicity, religion, gender)\n",
    "df = df[df[\"sentiment\"]!=\"other_cyberbullying\"]\n",
    "sentiments = [\"religion\", \"age\", \"ethnicity\", \"gender\", \"not bullying\"]\n",
    "\n",
    "# get word count for tweets\n",
    "tweet_length = []\n",
    "for text in df.tweet_clean:\n",
    "    tweet_len = len(text.split())\n",
    "    tweet_length.append(tweet_len)\n",
    "df['tweet_length'] = tweet_length\n",
    "# TODO: a word must contain at least 4 letters. this can be tested with 3\n",
    "df = df[df['tweet_length'] > 3]\n",
    "\n",
    "# number of letter\n",
    "df.sort_values(by=['tweet_length'], ascending=False)\n",
    "# limit chars to 120\n",
    "# TODO: must try 80, 100\n",
    "df = df[df['tweet_length'] < 120]\n",
    "max_length = np.max(df['tweet_length'])\n",
    "\n",
    "# convert sentiments to numbers \n",
    "df['sentiment'] = df['sentiment'].replace(\n",
    "    {\n",
    "        'religion':0,\n",
    "        'age':1,\n",
    "        'ethnicity':2,\n",
    "        'gender':3,\n",
    "        'not_cyberbullying':4\n",
    "    }\n",
    ")\n",
    "\n",
    "# split the data into test and train \n",
    "X = df['tweet_clean']\n",
    "y = df['sentiment']\n",
    "# train and test splitting: \n",
    "# %20 -> Test\n",
    "# %80 -> Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=seed_value\n",
    ")\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "# create token matrix with tweets\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_cv =  count_vectorizer.fit_transform(X_train)\n",
    "X_test_cv = count_vectorizer.transform(X_test)\n",
    "\n",
    "# TF-IDF: Term Frequency-Inverse Document Frequency\n",
    "# shows the importance of a word in the document\n",
    "#       number of times the word appears in the document \n",
    "# TF = ---------------------------------------------------\n",
    "#           total number of words in the document\n",
    "#\n",
    "#                  number of documents in the corpus\n",
    "# IDF = log(-----------------------------------------------) \n",
    "#            number of documents that contains the word +1\n",
    "#\n",
    "# TF-IDF = TF * IDF\n",
    "# TODO: can be improved with other params.\n",
    "term_freq_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
    "X_train_tf = term_freq_transformer.transform(X_train_cv)\n",
    "X_test_tf = term_freq_transformer.transform(X_test_cv)\n",
    "\n",
    "# TODO: can be tested with other params, (alpha value)\n",
    "multinominal_naive_bayes = MultinomialNB()\n",
    "multinominal_naive_bayes.fit(X_train_tf, y_train)\n",
    "prediction_results = multinominal_naive_bayes.predict(X_test_tf)\n",
    "\n",
    "accuracy_percentage = classification_report(\n",
    "    y_test, \n",
    "    prediction_results, \n",
    "    target_names = sentiments,\n",
    "    output_dict = True\n",
    ")['accuracy']*100\n",
    "\n",
    "print(\n",
    "    'Algorithm : Naive Bayes\\n',\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        prediction_results,\n",
    "        target_names = sentiments,\n",
    "        labels = [0, 1, 2, 3, 4]\n",
    "    )\n",
    ")\n",
    "print(f\"Elapsed time in seconds for Naive-Bayes:  {round(time.time()-start_time, 2)}s\")\n",
    "print(\n",
    "    f\"Considering the tweets of the user, \\n\"\n",
    "    f\"it was decided that this user is a cyberbully with:\\n\"\n",
    "    f\"Probability\\t{get_cyberbully_prob(prediction_results)}%\\n\"\n",
    "    f\"Accuracy\\t{round(accuracy_percentage, 2)}%\\n\"\n",
    ")\n",
    "\n",
    "#\n",
    "#  ___                   _  __                 _    \n",
    "# / _ \\ ______ _ _ __   | |/ /___  _   _ _   _| | __\n",
    "#| | | |_  / _` | '_ \\  | ' // _ \\| | | | | | | |/ /\n",
    "#| |_| |/ / (_| | | | | | . \\ (_) | |_| | |_| |   < \n",
    "# \\___//___\\__,_|_| |_| |_|\\_\\___/ \\__, |\\__,_|_|\\_\\\n",
    "#                                  |___/            \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "new_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
